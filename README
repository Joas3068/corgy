Code for a senior assistive robot using computer vision & voice commands to interact with a user.

main.c: Microcoontroller code. Responsible for sending motor commands based on UART data received from the ODROID

follow.py: When activated by a voice command it follows a unique object for a set amount of time. Uses haarcascades to identify a custom image. Outputs UART data based on object location.
Possibly remove time.sleep after UART commands.

FPS.py: This is the class that handles the threading implementation. Hopefully speeding up image
recognition. 






